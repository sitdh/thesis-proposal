@book{Myers:2004:AST:983238,
    author = {Myers, Glenford J and Sandler, Corey},
    isbn = {0471469122},
    mendeley-groups = {Standard},
    publisher = {John Wiley {\&} Sons},
    title = {{The Art of Software Testing}},
    year = {2004}
}


% - - - - - - - - - -
% Call graph
% - - - - - - - - - -
@article{Ryder1979,
    abstract = { The proliferation of large software systems written in high level programming languages insures the utility of analysis programs which examine interprocedural communications. Often these analysis programs need to reduce the dynamic relations between procedures to a static data representation. This paper presents one such representation, a directed, acyclic graph named the call graph of a program. We delineate the programs representable by an acyclic call graph and present an algorithm for constructing it using the property that its nodes may be linearly ordered. We prove the correctness of the algorithm and discuss the results obtained from an implementation of the algorithm in the PFORT Verifier [1].},
    author = {Ryder, Barbara G.},
    doi = {10.1109/TSE.1979.234183},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Graph/01702621.pdf:pdf},
    isbn = {0098-5589},
    issn = {00985589},
    journal = {IEEE Transactions on Software Engineering},
    keywords = {Fortran,Index Terms-Call graph,PFORT verifier,portability,procedure parameters,procedure references,static program analysis},
    mendeley-groups = {Graph},
    number = {3},
    pages = {216--226},
    pmid = {386},
    title = {{Constructing the Call Graph of a Program}},
    volume = {SE-5},
    year = {1979}
}

@book{39323220090101,
    Abstract = {Click here for a review of this titleThis book is for math and computer science majors, for students and representatives of many other disciplines (like bioinformatics, for example) taking courses in graph theory, discrete mathematics, data structures, algorithms. It is also for anyone who wants to understand the basics of graph theory, or just is curious. No previous knowledge in graph theory or any other significant mathematics is required. The very basic facts from set theory, proof techniques and algorithms are sufficient to understand it; but even those are explained in the text. Structurally, the text is divided into two parts where Part II is the generalization of Part I. The first part discusses the key concepts of graph theorywith emphasis on trees, bipartite graphs, cycles, chordal graphs, planar graphs and graph coloring. The second part considers generalizations of Part I and discusses hypertrees, bipartite hypergraphs, hypercycles, chordal hypergraphs, planar hypergraphs },
    Author = {Voloshin, Vitaly I.},
    ISBN = {9781606923726},
    Publisher = {Nova Science Publishers, Inc},
    Title = {Introduction to Graph and Hypergraph Theory.},
    URL = {http://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=393232&site=eds-live&authtype=ip,uid},
    Year = {2009},
}

% - - - - - - - - - -
% Regression cost model
% - - - - - - - - - -
@article{Jiang2015,
    abstract = {Software testing aims to search a set of test data in the entire search space to satisfy a certain standard of coverage. Therefore, finding an effective approach for automatic test data generation is a key issue of software testing. This paper proposes a new approach of reduced adaptive particle swarm optimization for generating the test data automatically. First, the approach reduces the particle swarm evolution equations and gets an evolution equation without velocity. Then, the approach makes an adaptive adjustment scheme based on inertia weight for the reduced evolution equation, which is different from the methods that directly act on the particle velocity in the past. The approach directly impacts on the particle position, namely actual problem solution. Next, according to the particle fitness and the particle aggregation degree, the population will be divided into three parts and inertia weight of each part will be designed accordingly. This can balance the search capabilities of algorithm between global and local. Finally, the approach is applied to automatic test data generation. The experiments results show that our approach can enhance convergence speed of algorithm and solve the problems that particle swarm algorithm easily falls into the local optimal solution and has low search accuracy. The experiments results also turn out that our approach can improve the efficiency of generating test data automatically.},
    author = {Jiang, Shujuan and Shi, Jiaojiao and Zhang, Yanmei and Han, Han},
    doi = {10.1016/j.neucom.2015.01.062},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0925231215001095-main.pdf:pdf},
    isbn = {0925-2312},
    issn = {18728286},
    journal = {Neurocomputing},
    keywords = {Adaptive adjustment scheme,Inertia weight,Particle aggregation degree,Particle swarm algorithm,Test data generation},
    mendeley-groups = {Test data generate},
    pages = {109--116},
    publisher = {Elsevier},
    title = {{Automatic test data generation based on reduced adaptive particle swarm optimization algorithm}},
    url = {http://dx.doi.org/10.1016/j.neucom.2015.01.062},
    volume = {158},
    year = {2015}
}
@article{Lemos2013,
    abstract = {This paper reports on a historical perspective of the evaluation studies present in software testing research published in the Brazilian Symposium on Software Engineering (SBES) in comparison to the International Conference on Software Engineering (ICSE). The survey characterizes the software testing-related papers published in the 25-year history of SBES, investigates the types of evaluation presented in these publications, and how the rate of evaluations has evolved over the years. A similar analysis within the same period is made for ICSE, allowing for a comparison between the national and international scenario. Results show that the rate of papers that present evaluation studies in SBES has significantly increased over the years. However, among the papers that described some kind of evaluation, only around 20{\%} performed more rigorous evaluations (i.e. case studies, quasi experiments, or controlled experiments). Such percentage is low when compared to ICSE, which presented 40{\%} of papers with more rigorous evaluations within the same period. Nevertheless, we noticed that both venues still lack the publication of research reporting controlled experiments: only a single paper in each conference presented this type of evaluation. ?? 2012 Elsevier Inc.},
    author = {Lemos, Ot{\'{a}}vio Augusto Lazzarini and Ferrari, Fabiano Cutigi and Eler, Marcelo Medeiros and Maldonado, Jos{\'{e}} Carlos and Masiero, Paulo Cesar},
    doi = {10.1016/j.jss.2012.11.040},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0164121212003238-main.pdf:pdf},
    issn = {01641212},
    journal = {Journal of Systems and Software},
    keywords = {Evaluation studies,Software testing,Software testing research in Brazil},
    mendeley-groups = {Test data generate},
    number = {4},
    pages = {951--969},
    publisher = {Elsevier Inc.},
    title = {{Evaluation studies of software testing research in Brazil and in the world: A survey of two premier software engineering conferences}},
    url = {http://dx.doi.org/10.1016/j.jss.2012.11.040},
    volume = {86},
    year = {2013}
}
@article{Mohi-Aldeen2016,
    author = {Mohi-Aldeen, Shayma Mustafa and Mohamad, Radziah and Deris, Safaai},
    doi = {10.1016/j.asoc.2016.09.044},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S1568494616305038-main.pdf:pdf},
    issn = {15684946},
    journal = {Applied Soft Computing},
    mendeley-groups = {Test data generate},
    publisher = {Elsevier B.V.},
    title = {{Application of Negative Selection Algorithm (NSA) for Test Data Generation of Path Testing}},
    url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494616305038},
    year = {2016}
}
@article{Nie2015,
    abstract = {Context: Software behavior depends on many factors, and some failures occur only when certain factors interact. This is known as an interaction triggered failure, and the corresponding selection of factor values can be modeled as a Minimal Failure-causing Schema (MFS). (An MFS involving m factors is an m-MFS.) Combinatorial Testing (CT) has been developed to exercise ("hit") all MFS with few tests. Adaptive Random Resting (ART) endeavors to make tests as different as possible, ensuring that testing of MFS is not unnecessarily repeated. Random Testing (RT) chooses tests at random without regard to the MFS already treated. CT might be expected to improve on RT for finding interaction triggered faults, and yet some studies report no significant difference. CT can also be expected to be better than ART, and yet other studies report that ART can be much better than RT. In light of these, the relative merits of CT, ART, and RT for finding interaction triggered faults are unclear. Objective: To investigate the relationships among CT, ART, and RT, we conduct the first complete and systematic comparison for the purpose of hitting MFS. Method: A systematic review of six aspects of CT, RT and ART is conducted first. Then two kinds of experiments are used to compare them under four metrics. Results: ART improves upon RT, but t-way CT is better than both. In hitting t'-MFS the advantage is typically in the range from 10{\%} to 30{\%} when t = t', but becomes much smaller when t' {\textless} t, and there may be no advantage when t' {\textgreater} t. The latter case may explain the studies reporting no significant difference between RT and CT. Conclusion: RT is easily implemented. However, depending on its implementation, ART can improve upon RT. CT does as well as ART whether or nott' = t, but provides a valuable improvement in the cases when t' = t.},
    author = {Nie, Changhai and Wu, Huayao and Niu, Xintao and Kuo, Fei Ching and Leung, Hareton and Colbourn, Charles J.},
    doi = {10.1016/j.infsof.2015.02.008},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0950584915000440-main.pdf:pdf},
    isbn = {0950-5849},
    issn = {09505849},
    journal = {Information and Software Technology},
    keywords = {Adaptive Random Testing (ART),Combinatorial Testing (CT),Interaction Triggered Failure (ITF),Minimal Failure-causing Schema (MFS),Software testing Random Testing (RT)},
    mendeley-groups = {Test data generate},
    number = {1},
    pages = {198--213},
    publisher = {Elsevier B.V.},
    title = {{Combinatorial testing, random testing, and adaptive random testing for detecting interaction triggered failures}},
    url = {http://dx.doi.org/10.1016/j.infsof.2015.02.008},
    volume = {62},
    year = {2015}
}
@article{Shahbaz2015,
    abstract = {Classic approaches to automatic input data generation are usually driven by the goal of obtaining program coverage and the need to solve or find solutions to path constraints to achieve this. As inputs are generated with respect to the structure of the code, they can be ineffective, difficult for humans to read, and unsuitable for testing missing implementation. Furthermore, these approaches have known limitations when handling constraints that involve operations with string data types. This paper presents a novel approach for generating string test data for string validation routines, by harnessing the Internet. The technique uses program identifiers to construct web search queries for regular expressions that validate the format of a string type (such as an email address). It then performs further web searches for strings that match the regular expressions, producing examples of test cases that are both valid and realistic. Following this, our technique mutates the regular expressions to drive the search for invalid strings, and the production of test inputs that should be rejected by the validation routine. The paper presents the results of an empirical study evaluating our approach. The study was conducted on 24 string input validation routines collected from 10 open source projects. While dynamic symbolic execution and search-based testing approaches were only able to generate a very low number of values successfully, our approach generated values with an accuracy of 34{\%} on average for the case of valid strings, and 99{\%} on average for the case of invalid strings. Furthermore, whereas dynamic symbolic execution and search-based testing approaches were only capable of detecting faults in 8 routines, our approach detected faults in 17 out of the 19 validation routines known to contain implementation errors.},
    author = {Shahbaz, Muzammil and McMinn, Phil and Stevenson, Mark},
    doi = {10.1016/j.scico.2014.04.008},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0167642314001725-main.pdf:pdf},
    issn = {01676423},
    journal = {Science of Computer Programming},
    keywords = {Regular expressions,Test data generation,Web searches},
    mendeley-groups = {Test data generate},
    number = {P4},
    pages = {405--425},
    publisher = {Elsevier B.V.},
    title = {{Automatic generation of valid and invalid test data for string validation routines using web searches and regular expressions}},
    url = {http://dx.doi.org/10.1016/j.scico.2014.04.008},
    volume = {97},
    year = {2015}
}
@article{Al-Refai2016,
    author = {Al-Refai, Mohammed and Ghosh, Sudipto and Cazzola, Walter},
    doi = {10.1109/ICST.2016.24},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Regression/07515480.pdf:pdf},
    isbn = {9781509018260},
    journal = {Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016},
    keywords = {JUnit tests,executable UML models,model-based dynamic adaptation,model-based regression test selection,model-based validation,unanticipated adaptation},
    mendeley-groups = {Test data generate},
    number = {3},
    pages = {288--298},
    title = {{Model-Based Regression Test Selection for Validating Runtime Adaptation of Software Systems}},
    year = {2016}
}

% - - - - - - - - - -
% Other
% - - - - - - - - - -
@article{HHailpern2002ailpern2002,
    abstract = {In commercial software development organizations, increased complexity of products, shortened development cycles, and higher customer expectations of quality have placed a major responsibility on the areas of software debugging, testing, and verification. As this issue of the IBM Systems Journal illustrates, there are exciting improvements in the underlying technology on all three fronts. However, we observe that due to the informal nature of software development as a whole, the prevalent practices in the industry are still immature, even in areas where improved technology exists. In addition, tools that incorporate the more advanced aspects of this technology are not ready for large-scale commercial use. Hence there is reason to hope for significant improvements in this area over the next several years.},
    author = {Hailpern, B. and Santhanam, P.},
    doi = {10.1147/sj.411.0004},
    file = {:Users/sitdh/Library/Application Support/Mendeley Desktop/Downloaded/Center - Unknown - Software Debugging Testing and Verification.pdf:pdf},
    isbn = {9111268611},
    issn = {0018-8670},
    journal = {IBM Systems Journal},
    mendeley-groups = {Testing},
    number = {1},
    pages = {4--12},
    title = {{Software debugging, testing, and verification}},
    volume = {41},
    year = {2002}
}
@article{Orso2014,
    abstract = {Despite decades ofwork by researchers and practitioners on numer- ous software quality assurance techniques, testing remains one of the most widely practiced and studied approaches for assessing and improving software quality. Our goal, in this paper, is to provide an accounting of some of the most successful research performed in software testing since the year 2000, and to present what appear to be some of the most significant challenges and opportunities in this area. To be more inclusive in this effort, and to go beyond our own personal opinions and biases, we began by contacting over 50 of our colleagues who are active in the testing research area, and asked them what they believed were (1) the most significant contributions to software testing since 2000 and (2) the greatest open challenges and opportunities for future research in this area. While our col- leagues' input (consisting of about 30 responses) helped guide our choice of topics to cover and ultimately the writing of this paper, we by no means claim that our paper represents all the relevant and noteworthy research performed in the area of software testing in the time period considered—a task that would require far more space and time than we have available. Nevertheless, we hope that the approach we followed helps this paper better reflect not only our views, but also those of the software testing community in general},
    author = {Orso, Alessandro and Rothermel, Gregg},
    doi = {10.1145/2593882.2593885},
    file = {:Users/sitdh/Library/Application Support/Mendeley Desktop/Downloaded/Orso, Rothermel - 2014 - Software testing a research travelogue (2000–2014).pdf:pdf},
    isbn = {9781450328654},
    journal = {Proceedings of the on Future of Software Engineering - FOSE 2014},
    keywords = {Software testing},
    mendeley-groups = {Testing},
    pages = {117--132},
    title = {{Software testing: a research travelogue (2000–2014)}},
    url = {http://dl.acm.org/citation.cfm?id=2593882.2593885},
    year = {2014}
}

@article{Luo2001,
    abstract = {Software testing is as old as the hills in the history of digital computers. The testing of software is an important means of assessing the software to determine its quality. Since testing typically consumes 40{\~{}}50{\%} of development efforts, and consumes more effort for systems that require higher levels of reliability, it is a significant part of the software engineering. With the development of Fourth generation languages (4GL), which speeds up the implementation process, the proportion of time devoted to testing increased. As the amount of maintenance and upgrade of existing systems grow, significant amount of testing will also be needed to verify systems after changes are made [12]. Despite advances in formal methods and verification techniques, a system still needs to be tested before it is used. Testing remains the truly effective means to assure the quality of a software system of non-trivial complexity [13], as well as one of the most intricate and least understood areas in software engineering [19]. Testing, an important research area within computer science is likely to become even more important in the future},
    author = {Luo, Lu},
    file = {:Users/sitdh/Library/Application Support/Mendeley Desktop/Downloaded/Luo - 2001 - Software testing techniques.pdf:pdf},
    isbn = {8177222600},
    journal = {Institute for software research international Carnegie mellon university Pittsburgh, PA},
    mendeley-groups = {Testing},
    number = {1-19},
    pages = {19},
    title = {{Software testing techniques}},
    volume = {15232},
    year = {2001}
}

@article{Mohi-Aldeen2016,
    author = {Mohi-Aldeen, Shayma Mustafa and Mohamad, Radziah and Deris, Safaai},
    doi = {10.1016/j.asoc.2016.09.044},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S1568494616305038-main.pdf:pdf},
    issn = {15684946},
    journal = {Applied Soft Computing},
    mendeley-groups = {Test data generate},
    publisher = {Elsevier B.V.},
    title = {{Application of Negative Selection Algorithm (NSA) for Test Data Generation of Path Testing}},
    url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494616305038},
    year = {2016}
}
@article{Jiang2015,
    abstract = {Software testing aims to search a set of test data in the entire search space to satisfy a certain standard of coverage. Therefore, finding an effective approach for automatic test data generation is a key issue of software testing. This paper proposes a new approach of reduced adaptive particle swarm optimization for generating the test data automatically. First, the approach reduces the particle swarm evolution equations and gets an evolution equation without velocity. Then, the approach makes an adaptive adjustment scheme based on inertia weight for the reduced evolution equation, which is different from the methods that directly act on the particle velocity in the past. The approach directly impacts on the particle position, namely actual problem solution. Next, according to the particle fitness and the particle aggregation degree, the population will be divided into three parts and inertia weight of each part will be designed accordingly. This can balance the search capabilities of algorithm between global and local. Finally, the approach is applied to automatic test data generation. The experiments results show that our approach can enhance convergence speed of algorithm and solve the problems that particle swarm algorithm easily falls into the local optimal solution and has low search accuracy. The experiments results also turn out that our approach can improve the efficiency of generating test data automatically.},
    author = {Jiang, Shujuan and Shi, Jiaojiao and Zhang, Yanmei and Han, Han},
    doi = {10.1016/j.neucom.2015.01.062},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0925231215001095-main.pdf:pdf},
    isbn = {0925-2312},
    issn = {18728286},
    journal = {Neurocomputing},
    keywords = {Adaptive adjustment scheme,Inertia weight,Particle aggregation degree,Particle swarm algorithm,Test data generation},
    mendeley-groups = {Test data generate},
    pages = {109--116},
    publisher = {Elsevier},
    title = {{Automatic test data generation based on reduced adaptive particle swarm optimization algorithm}},
    url = {http://dx.doi.org/10.1016/j.neucom.2015.01.062},
    volume = {158},
    year = {2015}
}

@article{Nie2015,
    abstract = {Context: Software behavior depends on many factors, and some failures occur only when certain factors interact. This is known as an interaction triggered failure, and the corresponding selection of factor values can be modeled as a Minimal Failure-causing Schema (MFS). (An MFS involving m factors is an m-MFS.) Combinatorial Testing (CT) has been developed to exercise ("hit") all MFS with few tests. Adaptive Random Resting (ART) endeavors to make tests as different as possible, ensuring that testing of MFS is not unnecessarily repeated. Random Testing (RT) chooses tests at random without regard to the MFS already treated. CT might be expected to improve on RT for finding interaction triggered faults, and yet some studies report no significant difference. CT can also be expected to be better than ART, and yet other studies report that ART can be much better than RT. In light of these, the relative merits of CT, ART, and RT for finding interaction triggered faults are unclear. Objective: To investigate the relationships among CT, ART, and RT, we conduct the first complete and systematic comparison for the purpose of hitting MFS. Method: A systematic review of six aspects of CT, RT and ART is conducted first. Then two kinds of experiments are used to compare them under four metrics. Results: ART improves upon RT, but t-way CT is better than both. In hitting t'-MFS the advantage is typically in the range from 10{\%} to 30{\%} when t = t', but becomes much smaller when t' {\textless} t, and there may be no advantage when t' {\textgreater} t. The latter case may explain the studies reporting no significant difference between RT and CT. Conclusion: RT is easily implemented. However, depending on its implementation, ART can improve upon RT. CT does as well as ART whether or nott' = t, but provides a valuable improvement in the cases when t' = t.},
    author = {Nie, Changhai and Wu, Huayao and Niu, Xintao and Kuo, Fei Ching and Leung, Hareton and Colbourn, Charles J.},
    doi = {10.1016/j.infsof.2015.02.008},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0950584915000440-main.pdf:pdf},
    isbn = {0950-5849},
    issn = {09505849},
    journal = {Information and Software Technology},
    keywords = {Adaptive Random Testing (ART),Combinatorial Testing (CT),Interaction Triggered Failure (ITF),Minimal Failure-causing Schema (MFS),Software testing Random Testing (RT)},
    mendeley-groups = {Test data generate},
    number = {1},
    pages = {198--213},
    publisher = {Elsevier B.V.},
    title = {{Combinatorial testing, random testing, and adaptive random testing for detecting interaction triggered failures}},
    url = {http://dx.doi.org/10.1016/j.infsof.2015.02.008},
    volume = {62},
    year = {2015}
}

@book{singh2011,
    title = "Software Testing:",
    author = "Yogesh Singh",
    year = "2011",
    month = "009",
    day = "006",
    doi = "10.1017/CBO9781139196185",
    abstract = "Software testing is conducted to provide stakeholders with information about the quality of a product under testing. The book, which is a result of the two decades of teaching experience of the author, aims to present testing concepts and methods that can be used in practice. The text will help readers to learn how to find faults in software before it is made available to users. A judicious mix of software testing concepts, solved problems and real-life case studies makes the book ideal for a basic course in software testing. The book will be a useful resource for senior undergraduate/graduate students of engineering, academics, software practitioners and researchers.",
    publisher = "Cambridge University Press",
    url = "https://www.cambridge.org/core/books/software-testing/ADF93C6EDB4761D9ACFE2DE987A0DBD2",
    isbn = "9781139196185",
    address = "Cambridge"
}

@book{Bourque2014,
    abstract = {SWEBOK V3.0 is the most recent completely revised and updated version of the internationally respected Guide to the Software Engineering Body of Knowledge. Newly imagined as a living, changing document, and thoroughly rewritten, SWEBOK V3.0 has been developed and created by leading authorities, reviewed by professionals, and made available for public review and comment, continuing its 20-year reputation as the most authoritative, fundamental, and trusted definition of the software engineering profession. SWEBOK V3.0 is comprised of 15 Knowledge Areas, plus a new Appendix on Standards. SWEBOK V3.0 is now specifically designed to be constantly reviewed and updated as technology and the engineering profession changes over time, remaining consistently relevant. Be sure to register to receive notifications when the SWEBOK Guide is revised.},
    author = {Bourque, Pierre and Fairley, Richard E.},
    booktitle = {IEEE Computer Society},
    doi = {10.1234/12345678},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Theory-of-Testing/SWEBOKv3.pdf:pdf},
    isbn = {0-7695-2330-7},
    issn = {07407459},
    mendeley-groups = {Testing},
    pages = {346},
    pmid = {13861254},
    title = {{Guide to the Software Engineering - Body of Knowledge.}},
    url = {www.swebok.org},
    year = {2014}
}

@article{Allen:1970:CFA:390013.808479,
    author = {Allen, Frances E.},
    title = {Control Flow Analysis},
    journal = {SIGPLAN Not.},
    issue_date = {July 1970},
    volume = {5},
    number = {7},
    month = jul,
    year = {1970},
    issn = {0362-1340},
    pages = {1--19},
    numpages = {19},
    url = {http://doi.acm.org/10.1145/390013.808479},
    doi = {10.1145/390013.808479},
    acmid = {808479},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@article{Anand2013,
    abstract = {Test case generation is among the most labour-intensive tasks in software testing. It also has a strong impact on the effectiveness and efficiency of software testing. For these reasons, it has been one of the most active research topics in software testing for several decades, resulting in many different approaches and tools. This paper presents an orchestrated survey of the most prominent techniques for automatic generation of software test cases, reviewed in self-standing sections. The techniques presented include: (a) structural testing using symbolic execution, (b) model-based testing, (c) combinatorial testing, (d) random testing and its variant of adaptive random testing, and (e) search-based testing. Each section is contributed by world-renowned active researchers on the technique, and briefly covers the basic ideas underlying the method, the current state of the art, a discussion of the open research problems, and a perspective of the future development of the approach. As a whole, the paper aims at giving an introductory, up-to-date and (relatively) short overview of research in automatic test case generation, while ensuring a comprehensive and authoritative treatment. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
    author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Yueh and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary Jean and McMinn, Phil},
    doi = {10.1016/j.jss.2013.02.061},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Theory-of-Testing/1-s2.0-S0164121213000563-main.pdf:pdf},
    isbn = {0164-1212},
    issn = {01641212},
    journal = {Journal of Systems and Software},
    keywords = {Adaptive random testing,Combinatorial testing,Model-based testing,Orchestrated survey,Search-based software testing,Software testing,Symbolic execution,Test automation,Test case generation},
    mendeley-groups = {Testing},
    number = {8},
    pages = {1978--2001},
    title = {{An orchestrated survey of methodologies for automated software test case generation}},
    volume = {86},
    year = {2013}
}

@article{Ma2016,
    author = {Ma, Lei and Artho, Cyrille and Zhang, Cheng and Sato, Hiroyuki and Gmeiner, Johannes and Ramler, Rudolf},
    doi = {10.1109/ASE.2015.49},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Random-Testing/07372010.pdf:pdf},
    isbn = {9781509000241},
    journal = {Proceedings - 2015 30th IEEE/ACM International Conference on Automated Software Engineering, ASE 2015},
    keywords = {Automatic test generation,Dynamic analysis,Random testing,Static analysis},
    mendeley-groups = {Random-Testing},
    pages = {212--223},
    title = {{GRT: Program-analysis-guided random testing}},
    year = {2016}
}

@article{Heaton2000,
    abstract = {Intonational characteristics of Thai sentences were used to evaluate fundamental frequency (F(0)) control in brain-damaged patients with unilateral left and right hemisphere lesions. Subjects (n = 41) included 9 young and 10 old normal adults, 12 right hemisphere patients, and 10 left hemisphere aphasic patients (7 fluent and 3 nonfluent). Sentences were comprised of six words, three of which were keywords occurring in sentence-initial, -medial, and -final positions. All 125 possible sequences of three of the five Thai tones (mid, low, falling, high, rising) were superimposed on monosyllabic keywords. Utterances were produced at a conversational speaking rate. Average F(0) of keywords was analyzed as a function of sentence position, tone, and group. For both normal and brain-damaged speakers, results indicated that tones in sentence-final position were significantly lower in F(0) than in either sentence-initial or -medial position; falling and high tones were significantly higher in F(0) than mid, low, and rising tones. Findings are discussed in relation to issues pertaining to hemispheric specialization and the nature of F(0) deficits in nonfluent and fluent aphasic patients},
    author = {Heaton, Kelly Bowman and Hawley, Michael and Benton, Stephen a},
    doi = {10.1007/11531142_22},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Random-Testing/eclat.pdf:pdf},
    isbn = {3-540-27992-X, 978-3-540-27992-1},
    issn = {03029743},
    journal = {Archives},
    mendeley-groups = {Random-Testing},
    number = {1994},
    pages = {174--196},
    title = {{Eclat: Automatic Generation and Classification of Test Inputs}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.2349{\&}rep=rep1{\&}type=pdf},
    volume = {58},
    year = {2000}
}

@phdthesis{Pacheco2005,
    abstract = {This thesis describes a technique that selects, from a large set of test inputs, a small subset likely to reveal faults in the software under test. The technique takes a program or software component, plus a set of correct executions-say, from observations of the software running properly, or from an existing test suite that a user wishes to enhance. The technique first infers an operational model of the software's operation. Then, inputs whose operational pattern of execution differs from the model in specific ways are suggestive of faults. These inputs are further reduced by selecting only one input per operational pattern. The result is a small portion of the original inputs, deemed by the technique as most likely to reveal faults. Thus, the technique can also be seen as an error-detection technique. The thesis describes two additional techniques that complement test input selection. One is a technique for automatically producing an oracle (a set of assertions) for a test input from the operational model, thus transforming the test input into a test case. The other is a classification-guided test input generation technique that also makes use of operational models and patterns. When generating inputs, it filters out code sequences that are unlikely to contribute to legal inputs, improving the efficiency of its search for fault-revealing inputs.(cont.) We have implemented these techniques in the Eclat tool, which generates unit tests for Java classes. Eclat's input is a set of classes to test and an example program execution- say, a passing test suite. Eclat's output is a set of JUnit test cases, each containing a potentially fault-revealing input and a set of assertions at least one of which fails. In our experiments, Eclat successfully generated inputs that exposed fault-revealing behavior; we have used Eclat to reveal real errors in programs. The inputs it selects as fault-revealing are an order of magnitude as likely to reveal a fault as all generated inputs.},
    author = {Pacheco, Carlos},
    doi = {http://hdl.handle.net/1721.1/33855},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Random-Testing/66277169-MIT.pdf:pdf},
    keywords = {Computer Science,Electrical Engineering},
    mendeley-groups = {Random-Testing},
    school = {Massachusetts Institute of Technology},
    title = {{Automatic generation and classification of test inputs}},
    url = {http://hdl.handle.net/1721.1/33855},
    year = {2005}
}

@ARTICLE{6363461, 
    author={H. Mei and D. Hao and L. Zhang and L. Zhang and J. Zhou and G. Rothermel}, 
    journal={IEEE Transactions on Software Engineering}, 
    title={A Static Approach to Prioritizing JUnit Test Cases}, 
    year={2012}, 
    volume={38}, 
    number={6}, 
    pages={1258-1275}, 
    abstract={Test case prioritization is used in regression testing to schedule the execution order of test cases so as to expose faults earlier in testing. Over the past few years, many test case prioritization techniques have been proposed in the literature. Most of these techniques require data on dynamic execution in the form of code coverage information for test cases. However, the collection of dynamic code coverage information on test cases has several associated drawbacks including cost increases and reduction in prioritization precision. In this paper, we propose an approach to prioritizing test cases in the absence of coverage information that operates on Java programs tested under the JUnit framework-an increasingly popular class of systems. Our approach, JUnit test case Prioritization Techniques operating in the Absence of coverage information (JUPTA), analyzes the static call graphs of JUnit test cases and the program under test to estimate the ability of each test case to achieve code coverage, and then schedules the order of these test cases based on those estimates. To evaluate the effectiveness of JUPTA, we conducted an empirical study on 19 versions of four Java programs ranging from 2K-80K lines of code, and compared several variants of JUPTA with three control techniques, and several other existing dynamic coverage-based test case prioritization techniques, assessing the abilities of the techniques to increase the rate of fault detection of test suites. Our results show that the test suites constructed by JUPTA are more effective than those in random and untreated test orders in terms of fault-detection effectiveness. Although the test suites constructed by dynamic coverage-based techniques retain fault-detection effectiveness advantages, the fault-detection effectiveness of the test suites constructed by JUPTA is close to that of the test suites constructed by those techniques, and the fault-detection effectiveness of the test suites constructed by some of - UPTA's variants is better than that of the test suites constructed by several of those techniques.}, 
    keywords={Java;program testing;regression analysis;software fault tolerance;JUPTA;JUnit test case prioritization techniques operating in the absence of coverage information;Java programs;dynamic code coverage information;dynamic coverage-based techniques;fault-detection effectiveness;regression testing;static approach;static call graphs;test case prioritization techniques;Regression analysis;Scheduling;Software testing;JUnit;Software testing;call graph;regression testing;test case prioritization}, 
    doi={10.1109/TSE.2011.106}, 
    ISSN={0098-5589}, 
    month={Nov},
}
