@article{HHailpern2002ailpern2002,
    abstract = {In commercial software development organizations, increased complexity of products, shortened development cycles, and higher customer expectations of quality have placed a major responsibility on the areas of software debugging, testing, and verification. As this issue of the IBM Systems Journal illustrates, there are exciting improvements in the underlying technology on all three fronts. However, we observe that due to the informal nature of software development as a whole, the prevalent practices in the industry are still immature, even in areas where improved technology exists. In addition, tools that incorporate the more advanced aspects of this technology are not ready for large-scale commercial use. Hence there is reason to hope for significant improvements in this area over the next several years.},
    author = {Hailpern, B. and Santhanam, P.},
    doi = {10.1147/sj.411.0004},
    file = {:Users/sitdh/Library/Application Support/Mendeley Desktop/Downloaded/Center - Unknown - Software Debugging Testing and Verification.pdf:pdf},
    isbn = {9111268611},
    issn = {0018-8670},
    journal = {IBM Systems Journal},
    mendeley-groups = {Testing},
    number = {1},
    pages = {4--12},
    title = {{Software debugging, testing, and verification}},
    volume = {41},
    year = {2002}
}
@article{Orso2014,
    abstract = {Despite decades ofwork by researchers and practitioners on numer- ous software quality assurance techniques, testing remains one of the most widely practiced and studied approaches for assessing and improving software quality. Our goal, in this paper, is to provide an accounting of some of the most successful research performed in software testing since the year 2000, and to present what appear to be some of the most significant challenges and opportunities in this area. To be more inclusive in this effort, and to go beyond our own personal opinions and biases, we began by contacting over 50 of our colleagues who are active in the testing research area, and asked them what they believed were (1) the most significant contributions to software testing since 2000 and (2) the greatest open challenges and opportunities for future research in this area. While our col- leagues' input (consisting of about 30 responses) helped guide our choice of topics to cover and ultimately the writing of this paper, we by no means claim that our paper represents all the relevant and noteworthy research performed in the area of software testing in the time period considered—a task that would require far more space and time than we have available. Nevertheless, we hope that the approach we followed helps this paper better reflect not only our views, but also those of the software testing community in general},
    author = {Orso, Alessandro and Rothermel, Gregg},
    doi = {10.1145/2593882.2593885},
    file = {:Users/sitdh/Library/Application Support/Mendeley Desktop/Downloaded/Orso, Rothermel - 2014 - Software testing a research travelogue (2000–2014).pdf:pdf},
    isbn = {9781450328654},
    journal = {Proceedings of the on Future of Software Engineering - FOSE 2014},
    keywords = {Software testing},
    mendeley-groups = {Testing},
    pages = {117--132},
    title = {{Software testing: a research travelogue (2000–2014)}},
    url = {http://dl.acm.org/citation.cfm?id=2593882.2593885},
    year = {2014}
}

@article{Luo2001,
    abstract = {Software testing is as old as the hills in the history of digital computers. The testing of software is an important means of assessing the software to determine its quality. Since testing typically consumes 40{\~{}}50{\%} of development efforts, and consumes more effort for systems that require higher levels of reliability, it is a significant part of the software engineering. With the development of Fourth generation languages (4GL), which speeds up the implementation process, the proportion of time devoted to testing increased. As the amount of maintenance and upgrade of existing systems grow, significant amount of testing will also be needed to verify systems after changes are made [12]. Despite advances in formal methods and verification techniques, a system still needs to be tested before it is used. Testing remains the truly effective means to assure the quality of a software system of non-trivial complexity [13], as well as one of the most intricate and least understood areas in software engineering [19]. Testing, an important research area within computer science is likely to become even more important in the future},
    author = {Luo, Lu},
    file = {:Users/sitdh/Library/Application Support/Mendeley Desktop/Downloaded/Luo - 2001 - Software testing techniques.pdf:pdf},
    isbn = {8177222600},
    journal = {Institute for software research international Carnegie mellon university Pittsburgh, PA},
    mendeley-groups = {Testing},
    number = {1-19},
    pages = {19},
    title = {{Software testing techniques}},
    volume = {15232},
    year = {2001}
}

@article{Mohi-Aldeen2016,
    author = {Mohi-Aldeen, Shayma Mustafa and Mohamad, Radziah and Deris, Safaai},
    doi = {10.1016/j.asoc.2016.09.044},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S1568494616305038-main.pdf:pdf},
    issn = {15684946},
    journal = {Applied Soft Computing},
    mendeley-groups = {Test data generate},
    publisher = {Elsevier B.V.},
    title = {{Application of Negative Selection Algorithm (NSA) for Test Data Generation of Path Testing}},
    url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494616305038},
    year = {2016}
}
@article{Jiang2015,
    abstract = {Software testing aims to search a set of test data in the entire search space to satisfy a certain standard of coverage. Therefore, finding an effective approach for automatic test data generation is a key issue of software testing. This paper proposes a new approach of reduced adaptive particle swarm optimization for generating the test data automatically. First, the approach reduces the particle swarm evolution equations and gets an evolution equation without velocity. Then, the approach makes an adaptive adjustment scheme based on inertia weight for the reduced evolution equation, which is different from the methods that directly act on the particle velocity in the past. The approach directly impacts on the particle position, namely actual problem solution. Next, according to the particle fitness and the particle aggregation degree, the population will be divided into three parts and inertia weight of each part will be designed accordingly. This can balance the search capabilities of algorithm between global and local. Finally, the approach is applied to automatic test data generation. The experiments results show that our approach can enhance convergence speed of algorithm and solve the problems that particle swarm algorithm easily falls into the local optimal solution and has low search accuracy. The experiments results also turn out that our approach can improve the efficiency of generating test data automatically.},
    author = {Jiang, Shujuan and Shi, Jiaojiao and Zhang, Yanmei and Han, Han},
    doi = {10.1016/j.neucom.2015.01.062},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0925231215001095-main.pdf:pdf},
    isbn = {0925-2312},
    issn = {18728286},
    journal = {Neurocomputing},
    keywords = {Adaptive adjustment scheme,Inertia weight,Particle aggregation degree,Particle swarm algorithm,Test data generation},
    mendeley-groups = {Test data generate},
    pages = {109--116},
    publisher = {Elsevier},
    title = {{Automatic test data generation based on reduced adaptive particle swarm optimization algorithm}},
    url = {http://dx.doi.org/10.1016/j.neucom.2015.01.062},
    volume = {158},
    year = {2015}
}

@article{Nie2015,
    abstract = {Context: Software behavior depends on many factors, and some failures occur only when certain factors interact. This is known as an interaction triggered failure, and the corresponding selection of factor values can be modeled as a Minimal Failure-causing Schema (MFS). (An MFS involving m factors is an m-MFS.) Combinatorial Testing (CT) has been developed to exercise ("hit") all MFS with few tests. Adaptive Random Resting (ART) endeavors to make tests as different as possible, ensuring that testing of MFS is not unnecessarily repeated. Random Testing (RT) chooses tests at random without regard to the MFS already treated. CT might be expected to improve on RT for finding interaction triggered faults, and yet some studies report no significant difference. CT can also be expected to be better than ART, and yet other studies report that ART can be much better than RT. In light of these, the relative merits of CT, ART, and RT for finding interaction triggered faults are unclear. Objective: To investigate the relationships among CT, ART, and RT, we conduct the first complete and systematic comparison for the purpose of hitting MFS. Method: A systematic review of six aspects of CT, RT and ART is conducted first. Then two kinds of experiments are used to compare them under four metrics. Results: ART improves upon RT, but t-way CT is better than both. In hitting t'-MFS the advantage is typically in the range from 10{\%} to 30{\%} when t = t', but becomes much smaller when t' {\textless} t, and there may be no advantage when t' {\textgreater} t. The latter case may explain the studies reporting no significant difference between RT and CT. Conclusion: RT is easily implemented. However, depending on its implementation, ART can improve upon RT. CT does as well as ART whether or nott' = t, but provides a valuable improvement in the cases when t' = t.},
    author = {Nie, Changhai and Wu, Huayao and Niu, Xintao and Kuo, Fei Ching and Leung, Hareton and Colbourn, Charles J.},
    doi = {10.1016/j.infsof.2015.02.008},
    file = {:Users/sitdh/OneDrive/Thesis/Papers/Test-data-gen/1-s2.0-S0950584915000440-main.pdf:pdf},
    isbn = {0950-5849},
    issn = {09505849},
    journal = {Information and Software Technology},
    keywords = {Adaptive Random Testing (ART),Combinatorial Testing (CT),Interaction Triggered Failure (ITF),Minimal Failure-causing Schema (MFS),Software testing Random Testing (RT)},
    mendeley-groups = {Test data generate},
    number = {1},
    pages = {198--213},
    publisher = {Elsevier B.V.},
    title = {{Combinatorial testing, random testing, and adaptive random testing for detecting interaction triggered failures}},
    url = {http://dx.doi.org/10.1016/j.infsof.2015.02.008},
    volume = {62},
    year = {2015}
}

@book{singh2011,
    title = "Software Testing:",
    author = "Yogesh Singh",
    year = "2011",
    month = "009",
    day = "006",
    doi = "10.1017/CBO9781139196185",
    abstract = "Software testing is conducted to provide stakeholders with information about the quality of a product under testing. The book, which is a result of the two decades of teaching experience of the author, aims to present testing concepts and methods that can be used in practice. The text will help readers to learn how to find faults in software before it is made available to users. A judicious mix of software testing concepts, solved problems and real-life case studies makes the book ideal for a basic course in software testing. The book will be a useful resource for senior undergraduate/graduate students of engineering, academics, software practitioners and researchers.",
    publisher = "Cambridge University Press",
    url = "https://www.cambridge.org/core/books/software-testing/ADF93C6EDB4761D9ACFE2DE987A0DBD2",
    isbn = "9781139196185",
    address = "Cambridge"
}

